version: '3.8'

services:
  # Database principale
  mongodb:
    image: mongo:6.0
    container_name: portal_mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-admin123}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE:-portal}
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongodb:/data/db
      - ./data/mongodb/backup:/backup
      - ./data/mongodb/scripts/init-db.js:/docker-entrypoint-initdb.d/init-db.js:ro
    networks:
      - portal_network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: portal_qdrant
    restart: unless-stopped
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    networks:
      - portal_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Cache Database
  redis:
    image: redis:7-alpine
    container_name: portal_redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis123} --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    networks:
      - portal_network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Nginx Proxy Manager
  nginx-proxy-manager:
    image: jc21/nginx-proxy-manager:latest
    container_name: portal_nginx_proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "81:81"
      - "443:443"
    volumes:
      - ./nginx/data:/data
      - ./nginx/letsencrypt:/etc/letsencrypt
    networks:
      - portal_network
    environment:
      DB_SQLITE_FILE: "/data/database.sqlite"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:81/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Monitoring: Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: portal_grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-worldmap-panel
      GF_FEATURE_TOGGLES_ENABLE: publicDashboards
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - portal_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Monitoring: Loki
  loki:
    image: grafana/loki:latest
    container_name: portal_loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki/config.yml:/etc/loki/local-config.yaml
      - ./data/loki:/loki
    networks:
      - portal_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Monitoring: Promtail
  promtail:
    image: grafana/promtail:latest
    container_name: portal_promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./monitoring/promtail/config.yml:/etc/promtail/config.yml
      - ./logs:/var/log
      - /var/log:/host/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
      - portal_network
    depends_on:
      - loki

volumes:
  grafana_data:
  loki_data:

networks:
  portal_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16 